{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hand_digit_recog.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3u2WiHTT4UyFN82bjKKuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jssaini7815/Hand-Digit-Recognition/blob/main/hand_digit_recog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjdXMkWbNBhK"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from skimage import img_as_ubyte\t\t\n",
        "from skimage.color import rgb2gray\n",
        "from keras.models import load_model\n",
        "\n",
        "width = 640\n",
        "height = 480\n",
        "cameraNo = 0\n",
        " \n",
        "cap = cv2.VideoCapture(cameraNo)\n",
        "cap.set(3,width)\n",
        "cap.set(4,height)\n",
        " \n",
        "\n",
        "model = load_model('trained_model.h5')\n",
        " \n",
        "while True:\n",
        "\tsuccess, img_original = cap.read()\n",
        "\timg_gray = rgb2gray(img_original)\n",
        "\n",
        "\n",
        "\timg_gray_u8 = img_as_ubyte(img_gray)\n",
        "\t#cv2.imshow(\"Window\", img_gray_u8)\n",
        "\t\n",
        "\t#Convert grayscale image to binary\n",
        "\t(thresh, im_binary) = cv2.threshold(img_gray_u8, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\t\n",
        "\n",
        "\timg_resized = cv2.resize(im_binary,(28,28))\n",
        "\n",
        "\t#invert image\n",
        "\tim_gray_invert = 255 - img_resized\n",
        "\tcv2.imshow(\"invert image\", im_gray_invert)\n",
        "\n",
        "\tim_final = im_gray_invert.reshape(1,28,28,1)\n",
        "\n",
        "\n",
        "\n",
        "\tans = model.predict(im_final)\n",
        "\tans = np.argmax(ans,axis=1)[0]\n",
        "\tprint(ans)\n",
        "\n",
        "\n",
        "\tcv2.putText(img_original,'Predicted Digit : '+str(ans),\n",
        "                    (50,50),cv2.FONT_HERSHEY_COMPLEX,\n",
        "                    1,(0,0,255),1)\n",
        "\n",
        "\tcv2.imshow(\"Original Image\",img_original)\n",
        "\tif cv2.waitKey(1) and 0xFF == ord('q'):\n",
        "\t\tbreak\n",
        "        \n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "'''\n",
        "Dataset subplots\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(10, 10, figsize=(8, 8), subplot_kw={'xticks':[], 'yticks':[]}, gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(x_train[i], cmap='binary', interpolation='nearest')\n",
        "    ax.text(0.05, 0.05, str(y_train[i]),transform=ax.transAxes, color='green')\n",
        "plt.show()\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}